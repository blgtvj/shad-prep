На ютубе таймстемпы в комментариях кликабельные. Здесь копии для удобства поиска сразу по всем видеозаписям.

# Оглавление

- [ШАД prep 2021 — линал 01](#шад-prep-2021--линал-01)
- [ШАД prep 2021 — линал 02](#шад-prep-2021--линал-02)
- [ШАД prep 2021 — линал 03](#шад-prep-2021--линал-03)
- [ШАД prep 2021 — линал 04](#шад-prep-2021--линал-04)
- [ШАД prep 2021 — линал 05](#шад-prep-2021--линал-05)


# ШАД prep 2021 — линал 01  

0:00:00 Вступительные слова о курсе.  

0:09:25 Система линейных уравнений, алгоритм Гаусса.  
0:16:24 Элементарные преобразования, они не меняют пространство решений.  
0:26:27 Ступенчатый вид, главные и свободные переменные.  
0:32:14 Улучшенный ступенчатый вид.  
0:35:45 Существование решений, три ситуации: решений нет, решение одно, решений бесконечное количество.  
0:53:27 Задача про количество главных переменных в зависимости от параметра, в домашнем задании есть похожая чуть сложнее.  

1:05:09 Матрицы, операции над ними.  
1:12:57 Важные примеры: матрица сдвига, у которой все нули, кроме единиц над диагональю, матрица цикла.  
Если у B в прозведении AB есть нулевой столбец, то и в результате будет там же нулевой.  
Аналогично, если у А в прозведении AB есть нулевая строка, то и в результате будет нулевая строка  
1:20:26 Умножение на диагональную матрицу слева или справа — строки или столбцы умножаются на диагональные элементы.  
1:25:53 Связь между системами линейных уравнений и операциями над матрицами.  
1:28:16 Хорошие свойства операций над матрицами: дистрибутивность, ассоциативность — чем матрицы похожи на числа.  
1:33:35 Плохие свойства: коммутативности нет, разные размеры в зависимости от порядка умножения.  
1:36:24 Простой пример, когда результат умножения разный в зависимости от порядка умножения.  
1:38:39 Делители нуля — произведение запросто может оказаться нулевым при ненулевых сомножителях, AB = 0.  
1:39:35 Произведение диагональных матриц, они коммутируют.  
1:40:29 Иллюстрация для интуиции: связь между диагональными матрицами и функции над конечными множествами.  
1:43:05 И еще никого не удивляет, что произведение двух ненулевых функций может оказаться нулевой функцией.  
1:44:42 Тот факт, что бывают делители нуля это не плохо, иначе у системы Ax=0 было бы лишь одно нулевое решение.  
1:45:37 Если матрица A широкая ▭, то у Ax=0 всегда существует ненулевое решение, за это мы их любим.  

1:48:53 Еще пара слов о программе курса.  

1:50:42 Нильпотенты – третий пример плохих свойств.  

—  

1:53:50 Перерыв, обсуждаем литературу по линейной алгебре: Винберг и Linear Algebra Done Right норм, еще материалы курсов на ФКН, а Кострикин это как машинный код, для роботов.  
1:57:05 Ответ на вопрос про здравое отношение взрослого человека к подробным доказательствам: прямая аналогия напрашивается про прикладных программистов и разработчиков компиляторов.  
   
—  

2:03:23 Задача из ДЗ: какие матрицы коммутируют с диагональной, ответ — диагональные.  

По ходу дела комментарий, что формализм и строгость — вещи малосвязанные. Так что бывают доказательства строгие и неформальные, мы ими и занимаемя, все наглядно, но без пробелов. А бывают с кучей формализма и нестрогие, с набором дыр.  

2:10:43 Задача из ДЗ: какие матрицы коммутируют с любыми матрицами, ответ — скалярные матрицы.  
2:27:03 Задача из ДЗ: какие матрицы коммутируют с матрицей J(0).  

2:42:44 Блочная формула умножения матриц.  
2:48:09 Частный случай: умножение AB как умножение A на блочную матрицу ( B_1 | ... | B_k).  
2:49:20 Иногда удобно произведение матриц AB рассматривать как сумму, если смотреть на них как на блочную строку A и блочный столбец B.  
2:52:35 Произведение двух блочных матриц вида (A B \\ 0 C), где нулевой блок.  

2:54:05 Транспонирование сложения и умножения, (AB)^t = B^t A^t и (A + B)^t = A^t + B^t.  
2:57:00 След матрицы tr(A), мы его будем позже обсуждать подробнее, а пока определение и важные свойства tr(AB) = tr(BA), tr(A + B) = tr(A) + tr(B).  

3:00:27 Деление и обратная матрица.  
Комментарий: можно потребовать любое из AB = E и BA = E, чтобы B была обратой, и доказательство не очевидно, но мы его пока не обсуждаем.  
3:04:24 Единственность обратной.  
3:06:27 Задача из ДЗ: пусть A прямоугольная, A B_1 = E_n и B_2 A = E_m, тогда m=n, то есть A квадратная — решается через след.  

3:10:04 Шесть эквивалентных определений невырожденности, по ходу курса добавятся еще два.  
Это удобно, когда надо перейти с одного языка на другой. Например, с языка про системы на язык про обратимость.  
В следующий раз будем обсуждать подробней. Когда видишь не первый раз, уже не так страшно.  
3:18:00 Задача из ДЗ: пусть A^m = 0, доказать обратимость матрицы E - A и найти ее явный вид.  

3:25:48 Завершающие слова: знание — это не какпокупка автомобиля, знание — это как спорт, тренер покажет путь, но заниматься надо самому.  

# ШАД prep 2021 — линал 02  
  
0:02:33 Матрицы, соответствующие элементарным преобразованиям.  
0:21:19 Замечание: если надо проделать преобразование строк, а потом преобразоавние слолбцов, то результат будет тот же, что если сделать в обратном порядке, сначала над столбцами, потом над строками: (U_1 A) U_2 = U_1 (A U_2)  
0:26:10 Замечание: когда мы решаем систему Ax = b, мы умножаем слева на матрицы элементарных преобразований, UAx = Ub  
0:27:50 Замечание: матрицы элементарных преобразований обратимы, явный вид обратных.  
0:34:37 Умножение и обратимость:  
(1) AB обратима   ⇔   A обратима и B обратима по отдельности;  
(2) (AB)^{-1} = B^{-1} A^{-1}  

0:41:04 Шесть эквивалентных определений невырожденности, по ходу курса добавятся еще два.  
0:56:10 Важный момент: обратимость имеет смысл только для квадратных матриц. Частая ошибка бывает, когда глядя на уравнения, записанные в матричном виде, забывают про это и сокращают на какую-нибудь прямоугольную матрицу.  
0:57:11 Быстрые критерии необратимости матриц.  
(1) Когда есть нулевая строка или столбец;  
(2) Если можно элементарными преобразованиеми занулить строку. Например, две строки одинаковые.  
1:07:30 В явном виде отрицание всех пунктов из эквивалентных определений невырожденности, для лучшего понимания.  

1:09:07 Поиск обратной матрицы: ( A | E ) ~> ( E | A^{-1} ), как это работает. 

1:24:29 Рассмотрим Ax=0 и Bx=0 для квадратных матриц одинаковой ширины. Мн-ва решений совпадают   ⇔   улучшенные ступенчатые виды A и B совпадают (если отбросить нули).  
В конспектах утверждение шире. Следующее эквивалентно:  
(1) Системы имеют одно и то же множество решений;     
(2) A приводится к B элементарными преобразованиями;  
(3) ∃ обратимая C: CA = B;  
(4) Улучшенные ступенчатые виды A и B совпадают (если отбросить нули).  
1:29:49 Ответ на вопрос: если улучшенный ступенчатый вид разный, то что будет с общими решениями?  
Утверждение выше про полное совпадение. Если надо пересечение, то к матрице A приписывается снизу матрица B   

1:31:31 Задача из ДЗ. Пусть A прямоугольная размера m×n, а B размера n×m. Утверждение:  E - AB обратима   ⇔   E - BA обратима.  
1:33:55 Пример применения этого утверждения. Матрица A — столбец, B — строка. Тогда AB — это большая матрица, а BA — это просто число. Так можно сокращать размер матрицы для проверки обратимости.  
1:37:00 Доказательство самого утверждения.  
1:50:25 Трюковое доказательство.  

2:12:58 Блочные элементарные преобразования.  
2:22:32 Пример.  

2:27:43 Подстановка матрицы в многочлен.  
2:30:44 Зануляющий многочлен. Примеры.  
2:32:52 Для любой матрицы существует зануляющий мн-н, причем deg p(t) ≤ n.  
Это сложно доказать, а вот это просто: deg p(t) ≤ n^2.  
2:35:47 Задача. Сама матрица A не дана, но дан зануляющий мн-н. Нужно выразить обратную матрицу через нее.  
2:39:08 Свойства подстановки в многочлен.  

2:46:13 Спектр матрицы. Пример: спектр диагональной матрицы.  
2:50:14 Матрицы с пустым вещественным спектром. При этом комплексный спектр всегда непуст.  
2:52:40 Свойства спектра.  

2:58:12 Минимальный многочлен.  

3:08:43 Ответ на вопрос, как готовиться.  

# ШАД prep 2021 — линал 03  

0:01:07 Определитель. Геометрическая интуиция про ориентированный объем.  
0:20:43 Три способа определить определитель.  
(1) Через единственность функции, согласованной с умножением матриц;  
(2) Через единственность полилинейной и кососимметрической функции на столбцах;  
(3) Через явную формулу с перестановками — это почти никогда не нужно.  
0:37:55 Пояснение, про структуру явной формулы.  
0:43:50 Определители для матриц 2x2 и 3x3.  
0:50:07 Как считать: табличный случай и правило по сведению произвольной матрицы к табличному случаю.  
Определитель матрицы в ступенчатом виде равен произведению элементов на диагонали.  
Простой геометрический пример со следующими матрицами:  
a b    a 0  
0 d    0 d  
0:56:19 Пояснение про определение через полилинейную и кососимметрическую функцию на столбцах.  
1:03:05 Как меняется определитель при элементарных преобразованиях.  
1:12:52 Пара быстрых способов выянить, равен ли определитель нулю.  
(-) Строчка или столбец нулевой;  
(-) Есть одинаковые или пропорциональные строки или столбцы.  
1:15:50 Еще пара свойств:  
(-) Транспонирование не меняет определитель;  
(-) Определитель единичной и скалярной матрицы;  
(-) det(λA) = λ^n det(A);  
(-) det(AB) = det(A) det(B).  
Определитель — единственная функция, которая уважает произведение.  
1:22:22 Важно, что сам определитель и определитель произведения det(AB) работают только на квадратных матрицах.  
1:24:09 Резюме по рассказанному об определителю.  
1:26:36 К эквивалентным определениям невырожденности добавляется еще один пункт про определитель.  
1:29:49 Определитель блочной матрицы  
A B  
0 D  
1:37:37 Ответ на вопрос и корректировка небольшого недопонимания про связь определителя верхнетреугольной матрицы и блочного определителя.  

1:47:00 Задача из ДЗ про определитель матирицы, где везде единицы, а на диагонали лямбды.  
1:53:33 Задача из ДЗ: определитель Вандермонда.  
2:03:00 Задача из ДЗ: дана матрица X = ( X_1 | ... | X_n ), нарезанная на столбцы и набор лямбд, надо посчитать det(λ_1 X_1 X_1^t + ... + λ_n X_n X_n^t). Ответ: det( X diag(λ_1, ..., λ_n) X^t ) = det(X)^2 λ_1, ..., λ_n  

2:12:03 Разложение определителя по столбцу или строке.  
2:19:40 Вычисление обратной матрицы через присоединенную матрицу. Это теоретический результат, когда мы можем сказать, что мы знаем, как выражаются элементы обратной через элементы исходной матрицы.  
2:25:10 Случай 2x2. Запоминается так: диагональные элементы меняются местами, у недиагональных меняется знак, все это делится на определитель.  

2:28:10 Характеристический многочлен.  
2:35:41 Свойства:  
(1) χ(λ) = λ^n - tr(A) λ^{n-1} + ... + (-1)^n det(A). Надо помнить второй и последний коэффициенты, а то, что скрывается за многоточием вряд ли понадобится;  
(2) Спектр — это корни характеристического многочлена;  
(3) теорема Гамильтона-Кэли: характеристический многочлен зануляет матрицу. Или, что то же самое, минимальный многочлен делит характеристический.  
2:44:30 Пример.  
2:47:54 Как быстро считать характеристический многочлен для матрицы 2x2: χ(λ) = λ^2 - tr(A) λ + det(A)  
2:48:52 Характеристический многочлен блочной матрицы: χ_S(λ) = χ_A(λ) χ_D(λ)  
A B  
0 D  
где A и D квадратные блоки.  
2:50:30 Замечание. A-λE обратима для всех лямбд, кроме конечного числа тех, что в спектре. И если была необратимая матрица, то ее легко сделать обратимой, сдвинув ее на λE почти для всех лямбд.  

2:52:18 Задача из ДЗ: принцип продолжения по непрерывности для определителя блочной матрицы, det( A B \ C D) = det(A) det( D - C A^{-1} B ), когда A обратима (здесь A — n×n, D — m×m).  
Получается умножением на матрицу элементарного преобразования (E 0 \ -CA^{-1} E).  
Эта формула близка к той, которую очень хотелось бы: det( A B \ C D) = det( AD - BC ), но во-первых, размеры A не позволяют внести ее во второй сомножитель, и во-вторых, A и C не обязательно коммутируют.  
3:01:28 Но если блоки квадратные и соседние коммутируют, то такая формула и получается.  
3:03:20 Решение этой задачи в два шага.  

# ШАД prep 2021 — линал 04  

0:00:50 Вспоминаем, что E-AB обратима  <=>  E-BA обратима. Сегодня разеберем, что для квадратных матриц spec(AB) = spec(BA). И χ_{AB}(t) = χ_{BA}(t). Для прямоугольных будут поправки к этому факту.  
0:03:12 Вспоминаем, что такое спектр.  
0:04:42 Равенство характеристических многочленов матриц AB и BA через продолжение по непрерывности.  
0:41:50 Минимальные многочлены матриц AB и BA не обязательно равны, пример: матрицы 2x2 заданы как A = diag(1, 0) и B = J(0), f_min(AB)=t^2, f_min(BA)=t.  
0:45:28 Когда матрица A широкая ▭, B высокая ▯: характеристические матриц AB и BA различаются на множитель t^{n-m}. Из этого еще следует, что spec(BA) = {0} ∪ spec{AB} — спектры различаются на включение нуля.  
0:50:06 Ответ на вопрос. Что будет, если дана квадратная матрица A с характеристическим χ_{A}(t) = t^k g(t), где g(t)≢0. Можно ли говорить, A раскладывается на произведение высокой ▯ и широкой ▭ матриц. Обсудим это позже, это про тензорный ранг.  
0:53:12 Доказательство, утверждения выше, что t^{n-m} χ_{AB}(t) = χ_{BA}(t).  
1:01:52 Резюме вышесказанного про AB и BA для квадратных и прямоугольных матриц.  

1:07:54 Векторные пространства. Конкретные и абстрактные.  
1:15:30 Определение из двух пунктов: интерфейс — множество со сложением и умножением на числа;  
1:23:20 И контракт — естественные аксиомы про сложение, умножение, единицу.  
1:29:47 Пара примеров векторных пространств: R^n, многочлены, функции на прямой.  
1:33:39 Еще важный пример: { y | Ay=0 } — множество решений однородной системы уравнений, со сложением и умножением. То есть, если есть два решения, то их сложение и умножение на числа останется в этом множестве.  
1:38:38 Подпространство. Это подмножество, которое замкнуто относительно сложения и умножения на скаляр. Важно, что оно тоже пространство. Пример выше есть подпространство в R^n, и его как пространство не сложней изучать, чем само R^n.  
1:41:08 Ответ на вопрос. Умножение u на v не задается. Многочлены можно перемножать, но для пространств это лишняя информация.  

1:42:25 Изоморфизм, биекция. Линейное отображние.  
1:49:10 Самое важное: любое линейное отображение φ: R^n -> R^m устроено как x -> Ax. И никаких других не бывает. То есть, в R^n любое линейное отображение — это то же самое, что умножить слева на матрицу.  
1:50:28 И еще важное: линейное отображение φ: R^n -> R^n из пространства в себя — это линейная деформация пространства. Это растяжения, наклоны, повороты, проекции, симметрии, etc.  
Все, что мы изучали про матрицы, будет важно, когда мы будем изучать линейные отображения.  
1:51:55 Еще важно, что любое /конечномерное/ пространство изоморфно R^n.  
То есть любое конечномерное пр-во (в каком-то смысле маленькое) будет устроено так же как R^n, и его изучать конечномерные пространства — все равно что изучать R^n.  
1:52:49 Ответ на вопрос: как определять одинаковость. Пример изоморфизма: нарезка матрицы вертикально в один длинный вертикальный вектор.  

1:55:19 Линейная зависимость.  
2:12:39 Базис — набор линейно-независимых векторов, через которые выражаются все в пространстве.  
Эквивалентные определения:  
Базис — максимально линейно-независимый набор. Добавить еще вектор не получится, поломается линейная-независимость.  
Базис — минимально-порождающий набор. Выкинуть вектор не получится.  
То есть, можно снизу вверх строить базис, а можно сверху вниз.  
И еще ∃! набор коэффициентов для выражения вектора в базисе. То есть, координаты вектора в базисе однозначны.  
2:18:49 Пример. Стандартный базис. Он есть в R^n и нет в других векторных пространствах. Чтобы были координаты, надо ввести какой-то базис.  
2:23:37 Размерность пространства — количество векторов в базисе. И если даны два базиса, то их размеры одинаковы.  
2:24:32 Если в каком-то пространстве V дан базис, то это сразу задает биекцию между V и R^n.  
2:27:09 Если V ⊇ U, то dim V ≥ dim U. И равенство достигается только при равенстве пространств.  
Это позволяет делать проверку того, что набор векторов является базисом.  
f_1, ..., f_m ∈ R^n  
Это базис или нет? Если m≠n, то нет.  
А если m=n, то еще проверяем: либо линейную независимость, либо то, что они порождающие. Достаточно половину определения проверить.  

2:29:14 Смена координат. Матрица перехода вектора из одного базиса в другой.  
2:38:31 Пример. Как искать эту матрицу в R^n.  
2:42:32 Ответ на вопрос про C^{-1} B C: как избавиться от C. Ответ: никак. Это матрицы, и они не коммутируют (за редким исключенем). Путаницу вызвало, что det(C^{-1} B C) = det(C^{-1}) det(B) det(C) = det(B), но здесь числа.   

2:44:16 Линейная оболочка.    
2:48:09 Все пространства устроены как R^n, и мы хотим теперь понять, как задавать подпространства в R^n.  
(-) С помощью линейных оболочек.  
(-) Через систему уравнений, { y | Ay = 0 }  
2:51:13 Пример A=(1 1), тогда пространство задается так: { (x y)^t | x+y=0 }, и через линейную оболочку: < (1, -1)^t >.  
Всегда можно пересчитать из одного способа задания в другой.  
Короткое замечание: rk(A) + rk(span) = n.  
2:54:17 Как найти базис, если пространство задано одним из способов выше. Вот первый:  
Задача: Задан набор векторов, надо среди них выбрать базис и остальные через него выразить.  
3:12:18 Скелетное разложение. Оно же ранговая факторизация.  
3:22:44 Задача: Подпространство задано матрицей, { y | Ay = 0 }, надо найти базис. Это называется ФСР — фундаментальная система решений.  

3:43:46 Обсуждение, как готовиться.  


# ШАД prep 2021 — линал 05  

0:02:37 Ранг матрицы.  
Следующие определения эквивалентны. И сами числа равны.  
(-) Столбцовый ранг  
(-) Строковый ранг  
(-) Факториальный ранг  
(-) Тензорный ранг  
(-) Минорный ранг  
(-) Количество главных переменных в улучшенном ступенчатом виде  
0:30:13 Как эти определения связаны. Самое главное — все эти ранги равны. То есть, это просто ранг.  
0:32:18 Пояснение, что факториальный ранг равен тензорному.  
0:41:02 Как считать ранг.  
0:45:14 Пара свойств:  
rk AC = rk DA = rk A, когда C и D обратимы  
rk A^t = rk A  
0:48:04 Пояснение, что строковый ранг равен столбцовому.  
0:54:16 Задача из ДЗ: посчитать ранг матрицы, где везде единицы, а на диагонали лямбды.  

1:02:52 Как искать представлеление для факториального и тензорного ранга. Вспоминаем ранговую факторизацию (скелетное разложение), а если ее раскрыть, то получается представление для тензорного ранга.  

1:09:17 rk A = 0   ⇔   A=0  
rk A = 1   ⇔   A = x y^t   — т.е. раскладывается в произведение ненулевых столбца и строки  

1:10:40 Задача из ДЗ: минорный ранг. Как найти максимальный минор: для этого сначала находим базис столбцов через ранговую факторизацию, а потом вторым Гауссом находим базис строк.  
1:14:50 Минорный ранг позволяет оценить ранг снизу: если видно, что какая-то подматрица невырождена, то ранг матрицы не меньше.  

1:17:40 Оценки рангов суммы и произведения.  
(-) \| rk A - rk B \| ≤ rk(A+B) ≤ rk A + rk B  
Причем обе оценки достигаются. Примеры на диагональных матрицах.  
То есть, если есть ранги слагаемых, не получится ранг суммы автоматом вычислить, его можно лишь оценить. И это лучшая оценка, которая есть.  
(-) rk A + rk B - k ≤ rk(AB) ≤ min(rk A, rk B)  
k — общая размерность, A размера m⨯k, B размера k⨯n  
Причем первое неравенство совсем не очевидно. Остальные оценки простые. Если есть задача на ранги, то велика вероятность, что в одном из шагов это неравенство.  

1:31:35 Количество главных переменных = rk A  
И dim { y | Ay=0 } = количество свободных переменных = n - rk A.  
1:33:16 Еще на всякий случай. Один из двух способов задания подпространства — через линейную оболочку. Размерность линейной оболочки равен рангу матрицы, составленной из векторов.  
1:34:14 Ранг квадратных матриц:  rk A = n   ⇔   det A ≠ 0  
Это восьмое эквивалентное определение невырожденности.  
1:35:00 Замечание. Два случая: det A ≠ 0 и det A = 0. В первом ранг полный. В остальных ранг показывает, насколько матрица вырожденна.  
Еще замечание ранг блочно-диагональной матрицы равен сумме рангов блоков на диагонали.  
1:38:37 Матрица A m⨯n может быть представлена в виде C F D, где C и D обратимы, а F прямоугольная с единицами на диагонали, причем их количество равно рангу A.  
Это достикается сначала приведением к ступенчатому виду по строкам, а потом по столбцам.  

1:43:40 Линейные отображения.  
1:45:57 Линейные операторы, из пространства в себя, это линейная деформация. Примеры.  
1:54:36 Как задавать линейное отображение из V в U.  
Выбираем базис в V и говорим, куда его векторы переходят в U, это однозначно задает всё линейное отображение.  
Векторы могут при этом переходить в одно и то же, и в ноль, это нормально.  

1:58:54 Задача. Проверить, существует ли отображение, которое переводит набор заданных векторов из V в заданные векторы U.  
2:06:26 Еще одно решение этой задачи: отображение задается матрицей с неизвестными коэффициентами, записываем все условия в одну большую систему уравнений и решаем ее.  
Но система может получиться довольно большой, можно устать ее решать.  
2:09:50 Что делать, если линейно-независимых векторов в данном нам наборе оказалось недостаточно для базиса всего пространства.  
Тогда берем и просто проверяем для линейной оболочки, которая представляет из себя подпространство, что есть такое отображение из него в U.  

2:16:46 Как дополнить набор векторов до базиса.  
2:26:55 Еще раз кратко предыдущая задача про проверку существования отображения с геометрическим пояснением и картинкой.  

2:36:35 Отображение из R^n в R^m. Матрица линейного отображения.  

2:55:06 Смена базиса. Матрица при замене координат.  

3:08:11 Ядро и образ.  
Ядра естественным образом задаются с помощью систем Ker φ = { x | Ax = 0 }  
Образы естественным образом задаются с помощью линейных оболочек Im φ = { Ax } = { x_1 A_1 + ... + x_n A_n } = < A_1, ..., A_n >  
3:13:11 dim Im Φ + dim Ker Φ = dim V  
Количество главных и свободных переменных.  
3:14:14 Геометрический смысл ядра и образа.  
Прообраз есть какое-то решение плюс ядро.  

3:19:45 Ответ на вопрос, что линейный оператор — отображение из R^n в R^n, в себя. Ввели отдельный термин, потому что отображение в другое пространоство и отображение в само себя по-разному себя ведут.  
